{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e18f0533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb097792",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c:\\Users\\saiom\\OneDrive\\Desktop\\college\\Plant' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8d85b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "GPU Name: NVIDIA GeForce RTX 3070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc763da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_DIR = r\"C:\\Users\\saiom\\OneDrive\\Desktop\\college\\Plant Disease Detection\\New Plant Diseases Dataset(Augmented)\"\n",
    "\n",
    "train_dir = os.path.join(DATA_DIR, \"train\")\n",
    "val_dir   = os.path.join(DATA_DIR, \"valid\")  \n",
    "test_dir  = os.path.join(DATA_DIR, \"test\")\n",
    "\n",
    "batch_size = 32\n",
    "lr         = 1e-3\n",
    "num_epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9728aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])\n",
    "    ]),\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])\n",
    "    ]),\n",
    "    \"test\": transforms.Compose([  # same as val\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])\n",
    "    ])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57ea7345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes (38): ['Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy', 'Blueberry___healthy', 'Cherry_(including_sour)___Powdery_mildew', 'Cherry_(including_sour)___healthy', 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Corn_(maize)___Common_rust_', 'Corn_(maize)___Northern_Leaf_Blight', 'Corn_(maize)___healthy', 'Grape___Black_rot', 'Grape___Esca_(Black_Measles)', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___healthy', 'Orange___Haunglongbing_(Citrus_greening)', 'Peach___Bacterial_spot', 'Peach___healthy', 'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy', 'Raspberry___healthy', 'Soybean___healthy', 'Squash___Powdery_mildew', 'Strawberry___Leaf_scorch', 'Strawberry___healthy', 'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___Late_blight', 'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Tomato_mosaic_virus', 'Tomato___healthy']\n",
      "#train: 70295, #val: 17572\n"
     ]
    }
   ],
   "source": [
    "assert os.path.isdir(train_dir), f\"{train_dir} not found\"\n",
    "assert os.path.isdir(val_dir),   f\"{val_dir} not found\"\n",
    "\n",
    "train_ds = datasets.ImageFolder(train_dir, transform=data_transforms[\"train\"])\n",
    "val_ds   = datasets.ImageFolder(val_dir,   transform=data_transforms[\"val\"])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True,\n",
    "                          num_workers=4, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size, shuffle=False,\n",
    "                          num_workers=4, pin_memory=True)\n",
    "\n",
    "print(f\"Classes ({len(train_ds.classes)}): {train_ds.classes}\")\n",
    "print(f\"#train: {len(train_ds)}, #val: {len(val_ds)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70bc2be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#test images: 33; examples: ['AppleCedarRust1.JPG', 'AppleCedarRust2.JPG', 'AppleCedarRust3.JPG', 'AppleCedarRust4.JPG', 'AppleScab1.JPG']\n"
     ]
    }
   ],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.folder     = folder\n",
    "        self.file_list  = [f for f in os.listdir(folder) \n",
    "                            if f.lower().endswith((\".jpg\",\".jpeg\",\".png\"))]\n",
    "        self.transform  = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.file_list[idx]\n",
    "        path  = os.path.join(self.folder, fname)\n",
    "        img   = Image.open(path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, fname\n",
    "\n",
    "# Setup test loader\n",
    "assert os.path.isdir(test_dir), f\"{test_dir} not found\"\n",
    "test_ds     = TestDataset(test_dir, transform=data_transforms[\"test\"])\n",
    "test_loader = DataLoader(test_ds, batch_size, shuffle=False,\n",
    "                         num_workers=0, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "print(f\"#test images: {len(test_ds)}; examples: {test_ds.file_list[:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb332d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saiom\\OneDrive\\Desktop\\college\\Plant Disease Detection\\venv310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\saiom\\OneDrive\\Desktop\\college\\Plant Disease Detection\\venv310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained VGG16\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "# Freeze feature extractor\n",
    "for p in model.features.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# Replace final layer\n",
    "num_classes = len(train_ds.classes)\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "\n",
    "# Move to device\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63b21c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6676f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    for imgs, labels in tqdm(loader, desc=\"Train\"):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outs = model(imgs)\n",
    "        loss = criterion(outs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss     += loss.item() * imgs.size(0)\n",
    "        running_corrects += (outs.argmax(1) == labels).sum().item()\n",
    "    return running_loss/len(loader.dataset), running_corrects/len(loader.dataset)\n",
    "\n",
    "def eval_epoch(model, loader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(loader, desc=\"Val  \"):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outs = model(imgs)\n",
    "            loss = criterion(outs, labels)\n",
    "\n",
    "            running_loss     += loss.item() * imgs.size(0)\n",
    "            running_corrects += (outs.argmax(1) == labels).sum().item()\n",
    "    return running_loss/len(loader.dataset), running_corrects/len(loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c3dde1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2197/2197 [05:38<00:00,  6.49it/s]\n",
      "Val  : 100%|██████████| 550/550 [01:15<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1513, Acc: 0.7627\n",
      " Val  Loss: 0.3554, Acc: 0.9141\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2197/2197 [05:33<00:00,  6.59it/s]\n",
      "Val  : 100%|██████████| 550/550 [01:13<00:00,  7.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8407, Acc: 0.8445\n",
      " Val  Loss: 0.3166, Acc: 0.9269\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2197/2197 [05:29<00:00,  6.67it/s]\n",
      "Val  : 100%|██████████| 550/550 [01:14<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7373, Acc: 0.8654\n",
      " Val  Loss: 0.2750, Acc: 0.9330\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2197/2197 [05:52<00:00,  6.24it/s]\n",
      "Val  : 100%|██████████| 550/550 [01:19<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6949, Acc: 0.8775\n",
      " Val  Loss: 0.3198, Acc: 0.9224\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2197/2197 [06:06<00:00,  5.99it/s]\n",
      "Val  : 100%|██████████| 550/550 [01:20<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6488, Acc: 0.8850\n",
      " Val  Loss: 0.2292, Acc: 0.9523\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2197/2197 [05:51<00:00,  6.24it/s]\n",
      "Val  : 100%|██████████| 550/550 [01:17<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6012, Acc: 0.8965\n",
      " Val  Loss: 0.2071, Acc: 0.9498\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2197/2197 [05:58<00:00,  6.12it/s]\n",
      "Val  : 100%|██████████| 550/550 [01:19<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5745, Acc: 0.9037\n",
      " Val  Loss: 0.2070, Acc: 0.9546\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2197/2197 [06:16<00:00,  5.84it/s]\n",
      "Val  : 100%|██████████| 550/550 [01:23<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5748, Acc: 0.9051\n",
      " Val  Loss: 0.2283, Acc: 0.9432\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2197/2197 [05:58<00:00,  6.12it/s]\n",
      "Val  : 100%|██████████| 550/550 [01:18<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5640, Acc: 0.9068\n",
      " Val  Loss: 0.1919, Acc: 0.9558\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 2197/2197 [05:52<00:00,  6.23it/s]\n",
      "Val  : 100%|██████████| 550/550 [01:14<00:00,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5225, Acc: 0.9132\n",
      " Val  Loss: 0.2748, Acc: 0.9511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    train_loss, train_acc = train_epoch(model, train_loader)\n",
    "    val_loss,   val_acc   = eval_epoch( model,   val_loader)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n",
    "    print(f\" Val  Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_vgg16.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e0f7340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test folder is flat; skipping labeled accuracy.\n"
     ]
    }
   ],
   "source": [
    "# If your test folder actually has class subfolders:\n",
    "if any(os.path.isdir(os.path.join(test_dir, c)) for c in train_ds.classes):\n",
    "    test_ds_labeled = datasets.ImageFolder(test_dir, transform=data_transforms[\"test\"])\n",
    "    test_loader_labeled = DataLoader(test_ds_labeled, batch_size, shuffle=False,\n",
    "                                     num_workers=0, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "    model.load_state_dict(torch.load(\"best_vgg16.pth\"))\n",
    "    test_loss, test_acc = eval_epoch(model, test_loader_labeled)\n",
    "    print(f\"\\nTest Accuracy (labeled): {test_acc*100:.2f}%\")\n",
    "else:\n",
    "    print(\"Test folder is flat; skipping labeled accuracy.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f45152f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiom\\AppData\\Local\\Temp\\ipykernel_9052\\2510907838.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_vgg16.pth\", map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions on flat test folder:\n",
      "AppleCedarRust1.JPG  →  Apple___Cedar_apple_rust\n",
      "AppleCedarRust2.JPG  →  Apple___Cedar_apple_rust\n",
      "AppleCedarRust3.JPG  →  Apple___Cedar_apple_rust\n",
      "AppleCedarRust4.JPG  →  Apple___Cedar_apple_rust\n",
      "AppleScab1.JPG  →  Apple___Apple_scab\n",
      "AppleScab2.JPG  →  Apple___Apple_scab\n",
      "AppleScab3.JPG  →  Tomato___Target_Spot\n",
      "CornCommonRust1.JPG  →  Corn_(maize)___Common_rust_\n",
      "CornCommonRust2.JPG  →  Corn_(maize)___Common_rust_\n",
      "CornCommonRust3.JPG  →  Corn_(maize)___Common_rust_\n",
      "PotatoEarlyBlight1.JPG  →  Potato___Early_blight\n",
      "PotatoEarlyBlight2.JPG  →  Potato___Early_blight\n",
      "PotatoEarlyBlight3.JPG  →  Tomato___Septoria_leaf_spot\n",
      "PotatoEarlyBlight4.JPG  →  Potato___Early_blight\n",
      "PotatoEarlyBlight5.JPG  →  Potato___Early_blight\n",
      "PotatoHealthy1.JPG  →  Potato___healthy\n",
      "PotatoHealthy2.JPG  →  Potato___healthy\n",
      "TomatoEarlyBlight1.JPG  →  Tomato___Early_blight\n",
      "TomatoEarlyBlight2.JPG  →  Tomato___Late_blight\n",
      "TomatoEarlyBlight3.JPG  →  Tomato___Target_Spot\n",
      "TomatoEarlyBlight4.JPG  →  Tomato___Bacterial_spot\n",
      "TomatoEarlyBlight5.JPG  →  Tomato___Target_Spot\n",
      "TomatoEarlyBlight6.JPG  →  Tomato___Early_blight\n",
      "TomatoHealthy1.JPG  →  Tomato___healthy\n",
      "TomatoHealthy2.JPG  →  Tomato___healthy\n",
      "TomatoHealthy3.JPG  →  Tomato___healthy\n",
      "TomatoHealthy4.JPG  →  Tomato___healthy\n",
      "TomatoYellowCurlVirus1.JPG  →  Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "TomatoYellowCurlVirus2.JPG  →  Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "TomatoYellowCurlVirus3.JPG  →  Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "TomatoYellowCurlVirus4.JPG  →  Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "TomatoYellowCurlVirus5.JPG  →  Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "TomatoYellowCurlVirus6.JPG  →  Tomato___Tomato_Yellow_Leaf_Curl_Virus\n"
     ]
    }
   ],
   "source": [
    "# Load best weights\n",
    "model.load_state_dict(torch.load(\"best_vgg16.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "print(\"\\nPredictions on flat test folder:\")\n",
    "with torch.no_grad():\n",
    "    for imgs, fnames in test_loader:\n",
    "        imgs  = imgs.to(device)\n",
    "        outs  = model(imgs)\n",
    "        preds = outs.argmax(1).cpu().tolist()\n",
    "        for f, p in zip(fnames, preds):\n",
    "            print(f\"{f}  →  {train_ds.classes[p]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "417c0976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def calculate_accuracy(model, test_dataset, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f105c712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiom\\AppData\\Local\\Temp\\ipykernel_9052\\4051244287.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_vgg16.pth\", map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No subfolders in test_dir; printing filename → prediction:\n",
      "AppleCedarRust1.JPG  →  Apple___Cedar_apple_rust\n",
      "AppleCedarRust2.JPG  →  Apple___Cedar_apple_rust\n",
      "AppleCedarRust3.JPG  →  Apple___Cedar_apple_rust\n",
      "AppleCedarRust4.JPG  →  Apple___Cedar_apple_rust\n",
      "AppleScab1.JPG  →  Apple___Apple_scab\n",
      "AppleScab2.JPG  →  Apple___Apple_scab\n",
      "AppleScab3.JPG  →  Tomato___Target_Spot\n",
      "CornCommonRust1.JPG  →  Corn_(maize)___Common_rust_\n",
      "CornCommonRust2.JPG  →  Corn_(maize)___Common_rust_\n",
      "CornCommonRust3.JPG  →  Corn_(maize)___Common_rust_\n",
      "PotatoEarlyBlight1.JPG  →  Potato___Early_blight\n",
      "PotatoEarlyBlight2.JPG  →  Potato___Early_blight\n",
      "PotatoEarlyBlight3.JPG  →  Tomato___Septoria_leaf_spot\n",
      "PotatoEarlyBlight4.JPG  →  Potato___Early_blight\n",
      "PotatoEarlyBlight5.JPG  →  Potato___Early_blight\n",
      "PotatoHealthy1.JPG  →  Potato___healthy\n",
      "PotatoHealthy2.JPG  →  Potato___healthy\n",
      "TomatoEarlyBlight1.JPG  →  Tomato___Early_blight\n",
      "TomatoEarlyBlight2.JPG  →  Tomato___Late_blight\n",
      "TomatoEarlyBlight3.JPG  →  Tomato___Target_Spot\n",
      "TomatoEarlyBlight4.JPG  →  Tomato___Bacterial_spot\n",
      "TomatoEarlyBlight5.JPG  →  Tomato___Target_Spot\n",
      "TomatoEarlyBlight6.JPG  →  Tomato___Early_blight\n",
      "TomatoHealthy1.JPG  →  Tomato___healthy\n",
      "TomatoHealthy2.JPG  →  Tomato___healthy\n",
      "TomatoHealthy3.JPG  →  Tomato___healthy\n",
      "TomatoHealthy4.JPG  →  Tomato___healthy\n",
      "TomatoYellowCurlVirus1.JPG  →  Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "TomatoYellowCurlVirus2.JPG  →  Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "TomatoYellowCurlVirus3.JPG  →  Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "TomatoYellowCurlVirus4.JPG  →  Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "TomatoYellowCurlVirus5.JPG  →  Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "TomatoYellowCurlVirus6.JPG  →  Tomato___Tomato_Yellow_Leaf_Curl_Virus\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1) Load best model weights\n",
    "model.load_state_dict(torch.load(\"best_vgg16.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# 2) Inspect test_dir\n",
    "subdirs = [d for d in os.listdir(test_dir) \n",
    "           if os.path.isdir(os.path.join(test_dir, d))]\n",
    "if subdirs:\n",
    "    # --- Labeled Test Set ---\n",
    "    print(\"Detected class‐subfolders in test_dir; computing accuracy…\")\n",
    "    test_labeled_ds = datasets.ImageFolder(test_dir, transform=data_transforms[\"test\"])\n",
    "    test_labeled_loader = DataLoader(\n",
    "        test_labeled_ds, batch_size, shuffle=False,\n",
    "        num_workers=0, pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_labeled_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            preds = outputs.argmax(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total   += labels.size(0)\n",
    "\n",
    "    print(f\"\\n✅ Test Accuracy: {100*correct/total:.2f}%  ({correct}/{total})\")\n",
    "\n",
    "else:\n",
    "    # --- Flat Test Folder ---\n",
    "    print(\"No subfolders in test_dir; printing filename → prediction:\")\n",
    "    # reuse your existing test_loader\n",
    "    with torch.no_grad():\n",
    "        for imgs, fnames in test_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            outputs = model(imgs)\n",
    "            preds = outputs.argmax(1).cpu().tolist()\n",
    "            for f, p in zip(fnames, preds):\n",
    "                print(f\"{f}  →  {train_ds.classes[p]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5b51ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference + accuracy on flat test folder…\n",
      "\n",
      "AppleCedarRust1.JPG  →  Apple___Cedar_apple_rust   (no GT match)\n",
      "AppleCedarRust2.JPG  →  Apple___Cedar_apple_rust   (no GT match)\n",
      "AppleCedarRust3.JPG  →  Apple___Cedar_apple_rust   (no GT match)\n",
      "AppleCedarRust4.JPG  →  Apple___Cedar_apple_rust   (no GT match)\n",
      "AppleScab1.JPG  →  Apple___Apple_scab   (no GT match)\n",
      "AppleScab2.JPG  →  Apple___Apple_scab   (no GT match)\n",
      "AppleScab3.JPG  →  Tomato___Target_Spot   (no GT match)\n",
      "CornCommonRust1.JPG  →  Corn_(maize)___Common_rust_   (no GT match)\n",
      "CornCommonRust2.JPG  →  Corn_(maize)___Common_rust_   (no GT match)\n",
      "CornCommonRust3.JPG  →  Corn_(maize)___Common_rust_   (no GT match)\n",
      "TomatoYellowCurlVirus1.JPG  →  Tomato___Tomato_Yellow_Leaf_Curl_Virus   (no GT match)\n",
      "TomatoYellowCurlVirus2.JPG  →  Tomato___Tomato_Yellow_Leaf_Curl_Virus   (no GT match)\n",
      "TomatoYellowCurlVirus3.JPG  →  Tomato___Tomato_Yellow_Leaf_Curl_Virus   (no GT match)\n",
      "TomatoYellowCurlVirus4.JPG  →  Tomato___Tomato_Yellow_Leaf_Curl_Virus   (no GT match)\n",
      "TomatoYellowCurlVirus5.JPG  →  Tomato___Tomato_Yellow_Leaf_Curl_Virus   (no GT match)\n",
      "TomatoYellowCurlVirus6.JPG  →  Tomato___Tomato_Yellow_Leaf_Curl_Virus   (no GT match)\n",
      "\n",
      "✅ Test Accuracy: 70.59%   (12/17)\n"
     ]
    }
   ],
   "source": [
    "import os, re, torch\n",
    "\n",
    "# Ensure model is in eval mode\n",
    "model.eval()\n",
    "\n",
    "# Build lookup: simplified → original class name\n",
    "lookup = {}\n",
    "for cls in train_ds.classes:\n",
    "    # Remove non-letters, lower-case\n",
    "    key = re.sub('[^a-z]', '', cls.lower())\n",
    "    lookup[key] = cls\n",
    "\n",
    "correct = total = 0\n",
    "\n",
    "print(\"Starting inference + accuracy on flat test folder…\\n\")\n",
    "with torch.no_grad():\n",
    "    for imgs, fnames in test_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        outs = model(imgs)\n",
    "        preds = outs.argmax(1).cpu().tolist()\n",
    "\n",
    "        for fname, p in zip(fnames, preds):\n",
    "            # 1. Simplify filename (drop extension and digits, non-letters)\n",
    "            base = os.path.splitext(fname)[0]  \n",
    "            simple = re.sub('[^a-z]', '', base.lower())\n",
    "\n",
    "            # 2. Lookup ground-truth\n",
    "            true_cls = lookup.get(simple, None)\n",
    "            pred_cls = train_ds.classes[p]\n",
    "\n",
    "            if true_cls is not None:\n",
    "                total += 1\n",
    "                if pred_cls == true_cls:\n",
    "                    correct += 1\n",
    "            else:\n",
    "                # no GT found for this file\n",
    "                print(f\"{fname}  →  {pred_cls}   (no GT match)\")\n",
    "\n",
    "# Report accuracy\n",
    "if total:\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"\\n✅ Test Accuracy: {acc:.2f}%   ({correct}/{total})\")\n",
    "else:\n",
    "    print(\"\\n⚠️ No ground-truth matches found—check your filename → class mapping.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c2b2898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save only the model’s learned parameters (recommended)\n",
    "torch.save(model.state_dict(), \"best_vgg16_weights.pth\")\n",
    "\n",
    "# (Optional) Save the full model (architecture + weights)\n",
    "torch.save(model, \"best_vgg16_full.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60ad4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saiom\\OneDrive\\Desktop\\college\\Plant Disease Detection\\venv310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\saiom\\OneDrive\\Desktop\\college\\Plant Disease Detection\\venv310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\saiom\\AppData\\Local\\Temp\\ipykernel_9052\\2510371426.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_WEIGHTS_PATH, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: C:\\Users\\saiom\\OneDrive\\Desktop\\college\\Plant Disease Detection\\New Plant Diseases Dataset(Augmented)\\straberryleaf.jpg\n",
      "Top‑3 predictions:\n",
      "  Strawberry___Leaf_scorch       100.00%\n",
      "  Apple___Apple_scab               0.00%\n",
      "  Apple___Black_rot                0.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import heapq\n",
    "\n",
    "# ─── CONFIG ─────────────────────────────────────────────────────────────\n",
    "MODEL_WEIGHTS_PATH = \"best_vgg16_weights.pth\"\n",
    "IMAGE_PATH         = r\"C:\\Users\\saiom\\OneDrive\\Desktop\\college\\Plant Disease Detection\\New Plant Diseases Dataset(Augmented)\\straberryleaf.jpg\"\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ─── REBUILD & LOAD MODEL ────────────────────────────────────────────────\n",
    "num_classes = len(train_ds.classes)\n",
    "model = models.vgg16(pretrained=False)\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "model.load_state_dict(torch.load(MODEL_WEIGHTS_PATH, map_location=DEVICE))\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# ─── INFERENCE PIPELINE (MATCHES VAL) ────────────────────────────────────\n",
    "infer_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# ─── PREDICT FUNCTION ───────────────────────────────────────────────────\n",
    "def predict_topk(image_path, model, transform, classes, k=3):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    x   = transform(img).unsqueeze(0).to(DEVICE)      \n",
    "    with torch.no_grad():\n",
    "        logits = model(x)[0]                           \n",
    "        probs  = torch.softmax(logits, dim=0).cpu().tolist()\n",
    "    # get top-k\n",
    "    topk = heapq.nlargest(k, range(len(probs)), key=lambda i: probs[i])\n",
    "    return [(classes[i], probs[i]) for i in topk]\n",
    "\n",
    "# ─── RUN & PRINT ─────────────────────────────────────────────────────────\n",
    "top3 = predict_topk(IMAGE_PATH, model, infer_transform, train_ds.classes, k=3)\n",
    "print(f\"Image: {IMAGE_PATH}\\nTop‑3 predictions:\")\n",
    "for cls, p in top3:\n",
    "    print(f\"  {cls:30s} {p*100:6.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
